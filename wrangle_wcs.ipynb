{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Communication Efficiency and Learnability of Colors using an Information Bottleneck Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ibhelpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from the World Color Survey\n",
    "df = pd.read_csv(\"wcs/term.txt\", delimiter=\"\\t\", header=None)\n",
    "df.columns = [\"language\", \"speaker\", \"chip\", \"word\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate prior probabilities\n",
    "\n",
    "For each language, $l$, we can use a frequentist approach (counts) to calculate the observed quantities of $p(w|c,l)$ and $p(c|w,l)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language  chip  word\n",
       "1         1     F       0.08\n",
       "                G       0.52\n",
       "                LB      0.36\n",
       "                LF      0.04\n",
       "          2     F       0.60\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_chip_count_df = df.groupby([\"language\", \"chip\", \"word\"]).speaker.agg(individual_count_per_word_per_chip=\"count\")\n",
    "total_word_count_df = df.groupby([\"language\", \"chip\"]).word.agg(total_words_per_chip=\"count\")\n",
    "\n",
    "# frequentist probability of a word given chip and language\n",
    "p_word_chip_language = per_chip_count_df[\"individual_count_per_word_per_chip\"] / total_word_count_df[\"total_words_per_chip\"]\n",
    "p_word_chip_language.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language  word  chip\n",
       "1         F     1       0.001366\n",
       "                2       0.010246\n",
       "                4       0.001366\n",
       "                5       0.011612\n",
       "                6       0.003415\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_word_count_df = df.groupby([\"language\", \"word\", \"chip\"]).speaker.agg(individual_count_per_chip_per_word=\"count\")\n",
    "total_chip_count_df = df.groupby([\"language\", \"word\"]).chip.agg(total_chips_per_word=\"count\")\n",
    "\n",
    "# frequentist probability of a chip given word and language\n",
    "p_chip_word_language = per_word_count_df[\"individual_count_per_chip_per_word\"] / total_chip_count_df[\"total_chips_per_word\"]\n",
    "p_chip_word_language.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Bottleneck\n",
    "\n",
    "Code taken from Frank (osfstorage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise components for optimising IB objective\n",
    "\n",
    "We need to initialise a joint prior distribution of words and meanings, i.e. `p_wm`, and a corresponding variational joint distribution, i.e. `q0` (q_wm_0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of possible meanings\n",
    "n_meanings = 330 #@TODO: change this with the correct number from WCS\n",
    "n_words = n_meanings\n",
    "# to avoid underflow problem\n",
    "eps = 0.0001\n",
    "\n",
    "q0 = (1 - eps) * np.eye(n_meanings) + eps * np.ones((n_meanings, n_meanings))\n",
    "\n",
    "# p_x = np.array([0.645, 0.161, 0.072, 0.040, 0.026, 0.018, 0.013, 0.010, 0.008, 0.006]) #p(m)\\n\n",
    "# to find p(m) - find the most common word for each chip and assign chip to that word\\n\n",
    "\n",
    "language = 1\n",
    "\n",
    "#Find the most common word for each chip and assign chip to that word\\n\n",
    "p_word_chip_language[1].groupby(level=0).idxmax()\n",
    "\n",
    "# convert words to indices\n",
    "words = p_chip_word_language[1].reset_index().word.unique()\n",
    "word_to_index =  {word: i for word, i in zip(words, range(len(words))) }\n",
    "index_to_word =  {i: word for word, i in zip(words, range(len(words))) }\n",
    "\n",
    "# assigne a word to each chip\n",
    "chip_to_word = np.zeros(n_meanings)\n",
    "for chip_num, word in p_word_chip_language[1].groupby(level=0).idxmax().values:\n",
    "    chip_to_word[chip_num-1] = word_to_index[word]\n",
    "\n",
    "# Find the frequency of that color in data, then split it equally across all the chips assigned to it\\n\n",
    "word_frequencies = p_chip_word_language[1].reset_index().word.apply(lambda x: word_to_index[x]).value_counts()\n",
    "\n",
    "p_x = np.zeros(n_meanings)\n",
    "for i in range(n_meanings):\n",
    "    p_x[i] = 1 / word_frequencies[chip_to_word[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate p_xGy using a PDF over chips in lab space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00920128, 0.00278018, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00414316, 0.00278018, 0.00278018, 0.00278565,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00278023, 0.00414316, 0.00280355, 0.00414316, 0.00278018,\n",
       "       0.00414316, 0.00377403, 0.00278018, 0.00278026, 0.00278018,\n",
       "       0.00278034, 0.00278018, 0.00414316, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00414316, 0.00278018, 0.00386399, 0.00278018,\n",
       "       0.00278018, 0.00605985, 0.00278018, 0.00278018, 0.00414316,\n",
       "       0.00278018, 0.0041559 , 0.0027802 , 0.00278018, 0.00414316,\n",
       "       0.00278023, 0.00278018, 0.00414316, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00278018, 0.00414316,\n",
       "       0.00278018, 0.00278018, 0.0027805 , 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00414316, 0.00278018, 0.0031551 , 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00414316, 0.00278019, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00278022, 0.00397387,\n",
       "       0.00414316, 0.00278018, 0.00278047, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00414109, 0.00278018, 0.00278022, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00368846, 0.00390259, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00404611, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00278025, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00414316, 0.00278018,\n",
       "       0.00414316, 0.00278018, 0.00278018, 0.00278018, 0.00414316,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00278018, 0.00296143,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00414316, 0.00278018, 0.00278018, 0.00278018, 0.00278438,\n",
       "       0.00278023, 0.00278018, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00287616, 0.00414316, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00460495, 0.00278023, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00278038, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00344862, 0.00278018,\n",
       "       0.0027802 , 0.00278018, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00279146, 0.00414316, 0.00278018, 0.00278018,\n",
       "       0.00414316, 0.00278018, 0.00278086, 0.00278018, 0.00414316,\n",
       "       0.00414316, 0.00278018, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00393214, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00414316, 0.0032092 , 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00278018, 0.00340787,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00414316, 0.00278018, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00414316, 0.00278018, 0.00414184,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00278018, 0.00297624,\n",
       "       0.00278018, 0.0036798 , 0.00377403, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278028, 0.00414316, 0.00278018, 0.00278018,\n",
       "       0.00414316, 0.00278018, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278022, 0.00278018, 0.00300857, 0.00278018,\n",
       "       0.00414316, 0.0028899 , 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00414316, 0.00278018, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00414316, 0.00278018, 0.00414323, 0.00286006, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00278018, 0.00414316,\n",
       "       0.00278018, 0.00350718, 0.00414316, 0.00278023, 0.00414827,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00414316, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00412927, 0.00278018,\n",
       "       0.00278269, 0.00278018, 0.00278018, 0.00278018, 0.00278023,\n",
       "       0.00278018, 0.00278018, 0.0027803 , 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00414316, 0.00337603, 0.00414316,\n",
       "       0.00278018, 0.00278022, 0.0028101 , 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278018, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00390259, 0.00278018, 0.00278018, 0.00278018,\n",
       "       0.00278018, 0.00278317, 0.00278018, 0.00278018, 0.00278018])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.special import softmax\n",
    "\n",
    "p_xGy = np.zeros((n_meanings, n_meanings))\n",
    "\n",
    "chip2lab = pd.read_csv(\"wcs/cnum-vhcm-lab-new.txt\", sep=\"\\t\", header=0, index_col=\"#cnum\")\n",
    "chip2lab = chip2lab.sort_values(by=\"#cnum\")[[\"L*\", \"a*\", \"b*\"]].copy().reset_index()\n",
    "\n",
    "labspace = chip2lab[[\"L*\", \"a*\", \"b*\"]].values\n",
    "\n",
    "eps = 1e-15\n",
    "for i in range(n_meanings):\n",
    "    # note the sum the pdf over the lab space dimension to go back into chip/meaning space \n",
    "    # (not sure if that's correct)\n",
    "    p_xGy[i] = softmax((norm.pdf(labspace, labspace[i], 1) + eps).sum(axis=1))\n",
    "\n",
    "p_xGy[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q0 = q0 / q0.sum(axis=1, keepdims=True) # q0 initial encoder - can set it to identity\n",
    "# betas = np.array([1. ** x for x in np.arange(10, 0, -1)])\n",
    "focalbeta = 1.0\n",
    "\n",
    "# calculate p_xy from p_x and p_xGy\n",
    "p_mGs = p_xGy / np.sum(p_xGy, axis=0)\n",
    "p_xGy = p_xGy / p_xGy.sum(axis=1, keepdims=True)\n",
    "p_xy = p_xGy * p_x[:, np.newaxis]\n",
    "p_xy = p_xy / np.sum(p_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1 , 1.09, 1.08, 1.07, 1.06, 1.05, 1.04, 1.03, 1.02, 1.01, 1.  ,\n",
       "       0.99, 0.98, 0.97, 0.96, 0.95, 0.94, 0.93, 0.92, 0.91, 0.9 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas = np.arange(1.1, 0.9, -0.01)\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1:1\n",
      "1.09:1\n",
      "1.08:1\n",
      "1.07:1\n",
      "1.06:1\n",
      "1.05:1\n",
      "1.04:1\n",
      "1.03:1\n",
      "1.02:1\n",
      "1.01:1\n",
      "1.0:1\n",
      "0.99:1\n",
      "0.98:1\n",
      "0.97:1\n",
      "0.96:1\n",
      "0.95:1\n",
      "0.94:1\n",
      "0.9299999999999999:1\n",
      "0.9199999999999999:1\n",
      "0.9099999999999999:1\n",
      "0.8999999999999999:1\n"
     ]
    }
   ],
   "source": [
    "q, beta, ibscores, qresult, qseq, qseqresults, allqs = fit_ib(p_xy, q0, focalbeta, betas, verbose=1)\n",
    "\n",
    "items = [str(x+1) for x in range(n_meanings)]\n",
    "columns = ['M'+str(i) for i in items]\n",
    "\n",
    "# create data frames for plotting and analysis\n",
    "ib_scores_df = pd.DataFrame(np.array(ibscores), columns = ['rate', 'distortion', 'elen'])\n",
    "ib_scores_df['beta'] = betas\n",
    "ib_scores_df['q'] = allqs\n",
    "ib_scores_df['Wn'] = [mergecols(q).shape[1] for q in ib_scores_df['q']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The structural phase transitions along the pareto frontier\n",
    "stochSys = []\n",
    "for i, q in enumerate(zip(qseq, qseqresults)):\n",
    "    for w in mergecols(q[0]).transpose():\n",
    "        stochSys.append([len(qseq)-i, q[1][0], q[1][1]] + list(w))\n",
    "\n",
    "stochSys = pd.DataFrame(data=np.array(stochSys), columns = ['n', 'rate', 'distortion'] + columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>rate</th>\n",
       "      <th>distortion</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>...</th>\n",
       "      <th>M321</th>\n",
       "      <th>M322</th>\n",
       "      <th>M323</th>\n",
       "      <th>M324</th>\n",
       "      <th>M325</th>\n",
       "      <th>M326</th>\n",
       "      <th>M327</th>\n",
       "      <th>M328</th>\n",
       "      <th>M329</th>\n",
       "      <th>M330</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.402207e-09</td>\n",
       "      <td>0.027163</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>0.00303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     n          rate  distortion       M1       M2       M3       M4       M5  \\\n",
       "0  1.0  2.402207e-09    0.027163  0.00303  0.00303  0.00303  0.00303  0.00303   \n",
       "\n",
       "        M6       M7  ...     M321     M322     M323     M324     M325  \\\n",
       "0  0.00303  0.00303  ...  0.00303  0.00303  0.00303  0.00303  0.00303   \n",
       "\n",
       "      M326     M327     M328     M329     M330  \n",
       "0  0.00303  0.00303  0.00303  0.00303  0.00303  \n",
       "\n",
       "[1 rows x 333 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stochSys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='rate'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEGCAYAAACO8lkDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZAUlEQVR4nO3df5TddX3n8eerCSRC+WUILiVsExtiDSViGFi39VQUsegKKRIldLeEQot6TuqyHntMtz1RsG7LHlaoVu2yglLOriBZYMPiSi24CwcVmYQABkgNFJeQbkkCxFgNMPW9f9xv9DLfC3MnM0wyyfNxzj1zv5/P5/uZzzt3Jq/7/X7v3JuqQpKkbj+3uxcgSdrzGA6SpBbDQZLUYjhIkloMB0lSy9TdvYDxcPjhh9fs2bN39zIkaVJZvXr1lqqa2atvrwiH2bNnMzg4uLuXIUmTSpLvv1Sfp5UkSS2GgySpxXCQJLXsFdccJO19XnjhBTZu3MiOHTt291ImvenTpzNr1iz222+/vvcxHCTtkTZu3MhBBx3E7NmzSbK7lzNpVRVbt25l48aNzJkzp+/9PK0kaY+0Y8cOZsyYYTCMURJmzJgx6iMww0HSHstgGB+78u/YVzgkOS3J+iQbkizv0T8tyfVN/z1JZjftpyZZneTB5uvbuvY5p2l/IMnXkhzetH88yZNJ1ja3d426KknSmIwYDkmmAJ8F3gnMB85JMn/YsAuAZ6pqLnA5cGnTvgU4vaqOA5YC1zZzTgX+HHhrVS0AHgCWdc13eVUd39y+usvVSdI4+vjHP85ll13GihUr+Ju/+ZuXHHfzzTfz0EMPjXr+4fuN9H1eSf0cOZwEbKiqx6rqeeA6YNGwMYuAa5r7K4FTkqSq7quqTU37OuBVSaYBaW4HpnO8czCwCUmaBC655BLe/va3v2T/roTD0NBQa7+Rvs8rqZ9wOAp4omt7Y9PWc0xVDQHbgBnDxpwFrKmq56rqBeCDwIN0QmE+cFXX2GXN6aarkxzWa1FJLkwymGRw8+bNfZQhSaP3yU9+knnz5vHmN7+Z9evXA3DeeeexcuVKAJYvX878+fNZsGABH/nIR/jmN7/JqlWr+IM/+AOOP/54Hn30UdauXcub3vQmFixYwJlnnskzzzwDwMknn8xFF13EwMAAl156aWu/7u9z++2388Y3vpHjjjuO888/n+eeew7ovH3Qxz72MRYuXMhxxx3HI488Mi51T8hLWZMcS+dU0zua7f3ohMMbgceAzwB/CPwJ8HngE0A1X/8TcP7wOavqSuBKgIGBAT/rVNqLXXzLOh7a9INxnXP+LxzMx04/9mXHrF69muuuu461a9cyNDTEwoULOeGEE37av3XrVm666SYeeeQRkvDss89y6KGHcsYZZ/Dud7+bxYsXA7BgwQI+85nP8Ja3vIUVK1Zw8cUXc8UVVwDw/PPP//S94b73ve+9aL+dduzYwXnnncftt9/OvHnzOPfcc/n85z/PRRddBMDhhx/OmjVr+NznPsdll13GF77whTH/+/Rz5PAkcHTX9qymreeY5nrCIcDWZnsWcBNwblU92ow/HqCqHq3Oh1h/BfjVpu0fquqfquonwH+hc1pLkibcXXfdxZlnnskBBxzAwQcfzBlnnPGi/kMOOYTp06dzwQUXcOONN3LAAQe05ti2bRvPPvssb3nLWwBYunQpd95550/7zz777BHXsX79eubMmcO8efN6zvGe97wHgBNOOIHHH3981HX20s+Rw73AMUnm0AmBJcBvDRuzis4F528Bi4E7qqqSHArcCiyvqru7xj8JzE8ys6o2A6cCDwMkObKq/r4Zdybw3V2qTNJeY6Rn+LvL1KlT+c53vsPtt9/OypUr+Yu/+AvuuOOOUc1x4IEHjnkd06ZNA2DKlCkMDQ2NeT7o48ihuYawDLiNzn/gX6mqdUkuSbIzRq8CZiTZAHwY2Ply12XAXGBF10tTj2guUl8M3JnkATpHEv+h2ec/7nyJK/BW4N+NS6WSNEq//uu/zs0338yPf/xjtm/fzi233PKi/h/+8Ids27aNd73rXVx++eXcf//9ABx00EFs374d6BxdHHbYYdx1110AXHvttT89ihiue79ur3vd63j88cfZsGHDiHOMl76uOTQvJ/3qsLYVXfd3AO/tsd+f0LmO0GvOvwT+skf7b/ezJkl6pS1cuJCzzz6bN7zhDRxxxBGceOKJL+rfvn07ixYtYseOHVQVn/rUpwBYsmQJv/d7v8enP/1pVq5cyTXXXMMHPvABfvSjH/Ha176WL37xiz2/3/D9dpo+fTpf/OIXee9738vQ0BAnnngiH/jAB165woF0TvlPbgMDA+WH/Uh7l4cffpjXv/71u3sZe41e/55JVlfVQK/xvn2GJKnFcJAktRgOkvZYe8Np7z3Brvw7Gg6S9kjTp09n69atBsQY7fw8h+nTp49qPz/sR9IeadasWWzcuBHfHmfsdn4S3GgYDpL2SPvtt9+oPrlM48vTSpKkFsNBktRiOEiSWgwHSVKL4SBJajEcJEkthoMkqcVwkCS1GA6SpBbDQZLUYjhIkloMB0lSi+EgSWoxHCRJLYaDJKnFcJAktRgOkqQWw0GS1GI4SJJaDAdJUktf4ZDktCTrk2xIsrxH/7Qk1zf99ySZ3bSfmmR1kgebr2/r2uecpv2BJF9LcnjT/uokX0/yvebrYeNUqySpTyOGQ5IpwGeBdwLzgXOSzB827ALgmaqaC1wOXNq0bwFOr6rjgKXAtc2cU4E/B95aVQuAB4BlzT7Lgdur6hjg9mZbkjSB+jlyOAnYUFWPVdXzwHXAomFjFgHXNPdXAqckSVXdV1WbmvZ1wKuSTAPS3A5MEuBgYFOPua4BfnP0ZUmSxqKfcDgKeKJre2PT1nNMVQ0B24AZw8acBaypqueq6gXgg8CDdEJhPnBVM+41VfX3zf3/B7ym16KSXJhkMMng5s2b+yhDktSvCbkgneRYOqea3t9s70cnHN4I/AKd00p/OHy/qiqges1ZVVdW1UBVDcycOfOVWrok7ZP6CYcngaO7tmc1bT3HNNcTDgG2NtuzgJuAc6vq0Wb88QBV9WgTAF8BfrXp+4ckRzb7Hgk8NbqSJElj1U843Asck2ROkv2BJcCqYWNW0bngDLAYuKOqKsmhwK3A8qq6u2v8k8D8JDuf8p8KPNxjrqXA/xhFPZKkcTB1pAFVNZRkGXAbMAW4uqrWJbkEGKyqVXSuF1ybZAPwNJ0Agc4rkOYCK5KsaNreUVWbklwM3JnkBeD7wHlN/58BX0lyQdP+vvEoVJLUv3TO6kxuAwMDNTg4uLuXIUmTSpLVVTXQq8+/kJYktRgOkqQWw0GS1GI4SJJaDAdJUovhIElqMRwkSS2GgySpxXCQJLUYDpKkFsNBktRiOEiSWgwHSVKL4SBJajEcJEkthoMkqcVwkCS1GA6SpBbDQZLUYjhIkloMB0lSi+EgSWoxHCRJLYaDJKnFcJAktRgOkqQWw0GS1NJXOCQ5Lcn6JBuSLO/RPy3J9U3/PUlmN+2nJlmd5MHm69ua9oOSrO26bUlyRdN3XpLNXX2/O37lSpL6MXWkAUmmAJ8FTgU2AvcmWVVVD3UNuwB4pqrmJlkCXAqcDWwBTq+qTUl+BbgNOKqqtgPHd32P1cCNXfNdX1XLxlaaJGlX9XPkcBKwoaoeq6rngeuARcPGLAKuae6vBE5Jkqq6r6o2Ne3rgFclmda9Y5J5wBHAXbtahCRpfPUTDkcBT3Rtb2zaeo6pqiFgGzBj2JizgDVV9dyw9iV0jhSqe2ySB5KsTHJ0H2uUJI2jCbkgneRYOqea3t+jewnw5a7tW4DZVbUA+Do/OyIZPueFSQaTDG7evHm8lyxJ+7R+wuFJoPvZ+6ymreeYJFOBQ4CtzfYs4Cbg3Kp6tHunJG8AplbV6p1tVbW16+jiC8AJvRZVVVdW1UBVDcycObOPMiRJ/eonHO4FjkkyJ8n+dJ7prxo2ZhWwtLm/GLijqirJocCtwPKqurvH3Ofw4qMGkhzZtXkG8HAfa5QkjaMRX61UVUNJltF5pdEU4OqqWpfkEmCwqlYBVwHXJtkAPE0nQACWAXOBFUlWNG3vqKqnmvvvA9417Ft+KMkZwFAz13m7XJ0kaZfkxdeBJ6eBgYEaHBzc3cuQpEklyeqqGujV519IS5JaDAdJUovhIElqMRwkSS2GgySpxXCQJLUYDpKkFsNBktRiOEiSWgwHSVKL4SBJajEcJEkthoMkqcVwkCS1GA6SpBbDQZLUYjhIkloMB0lSi+EgSWoxHCRJLYaDJKnFcJAktRgOkqQWw0GS1GI4SJJaDAdJUovhIElqMRwkSS19hUOS05KsT7IhyfIe/dOSXN/035NkdtN+apLVSR5svr6taT8oydqu25YkV7zcXJKkiTNiOCSZAnwWeCcwHzgnyfxhwy4AnqmqucDlwKVN+xbg9Ko6DlgKXAtQVdur6vidN+D7wI0jzCVJmiD9HDmcBGyoqseq6nngOmDRsDGLgGua+yuBU5Kkqu6rqk1N+zrgVUmmde+YZB5wBHDXy801mqIkSWPTTzgcBTzRtb2xaes5pqqGgG3AjGFjzgLWVNVzw9qXANdXVY1iLpJcmGQwyeDmzZv7KEOS1K8JuSCd5Fg6p4fe36N7CfDl0c5ZVVdW1UBVDcycOXOsS5QkdeknHJ4Eju7antW09RyTZCpwCLC12Z4F3AScW1WPdu+U5A3A1Kpa3c9ckqSJ0U843Asck2ROkv3pPNNfNWzMKjoXnAEWA3dUVSU5FLgVWF5Vd/eY+xzaRw095+pjnZKkcTJiODTn/ZcBtwEPA1+pqnVJLklyRjPsKmBGkg3Ah4GdL3ddBswFVnS9bPWIrunfRzscXmouSdIEyd7wpHxgYKAGBwd39zIkaVJJsrqqBnr1+RfSkqQWw0GS1GI4SJJaDAdJUovhIElqMRwkSS2GgySpxXCQJLUYDpKkFsNBktRiOEiSWgwHSVKL4SBJajEcJEkthoMkqcVwkCS1GA6SpBbDQZLUYjhIkloMB0lSi+EgSWoxHCRJLYaDJKnFcJAktRgOkqQWw0GS1GI4SJJa+gqHJKclWZ9kQ5LlPfqnJbm+6b8nyeym/dQkq5M82Hx9W9c++ye5MsnfJnkkyVlN+3lJNidZ29x+d5xqlST1aepIA5JMAT4LnApsBO5NsqqqHuoadgHwTFXNTbIEuBQ4G9gCnF5Vm5L8CnAbcFSzzx8BT1XVvCQ/B7y6a77rq2rZWIuTJO2afo4cTgI2VNVjVfU8cB2waNiYRcA1zf2VwClJUlX3VdWmpn0d8Kok05rt84E/Baiqn1TVlrEUIkkaP/2Ew1HAE13bG/nZs//WmKoaArYBM4aNOQtYU1XPJTm0aftEkjVJbkjymu6xSR5IsjLJ0b0WleTCJINJBjdv3txHGZKkfk3IBekkx9I51fT+pmkqMAv4ZlUtBL4FXNb03QLMrqoFwNf52RHJi1TVlVU1UFUDM2fOfEXXL0n7mn7C4Umg+9n7rKat55gkU4FDgK3N9izgJuDcqnq0Gb8V+BFwY7N9A7AQoKq2VtVzTfsXgBNGUY8kaRz0Ew73AsckmZNkf2AJsGrYmFXA0ub+YuCOqqrm9NGtwPKqunvn4KoqOkcIJzdNpwAPASQ5smveM4CHR1OQJGnsRny1UlUNJVlG55VGU4Crq2pdkkuAwapaBVwFXJtkA/A0nQABWAbMBVYkWdG0vaOqngI+2uxzBbAZ+J2m/0NJzgCGmrnOG3uZkqTRSOdJ/OQ2MDBQg4ODu3sZkjSpJFldVQO9+vwLaUlSi+EgSWoxHCRJLYaDJKnFcJAktRgOkqQWw0GS1GI4SJJaDAdJUovhIElqMRwkSS2GgySpxXCQJLUYDpKkFsNBktRiOEiSWgwHSVKL4SBJajEcJEkthoMkqcVwkCS1GA6SpBbDQZLUYjhIkloMB0lSi+EgSWoxHCRJLYaDJKmlr3BIclqS9Uk2JFneo39akuub/nuSzG7aT02yOsmDzde3de2zf5Irk/xtkkeSnPVyc0mSJs6I4ZBkCvBZ4J3AfOCcJPOHDbsAeKaq5gKXA5c27VuA06vqOGApcG3XPn8EPFVV85p5/88Ic0mSJkg/Rw4nARuq6rGqeh64Dlg0bMwi4Jrm/krglCSpqvuqalPTvg54VZJpzfb5wJ8CVNVPqmrLy8012sIkSbuun3A4Cniia3tj09ZzTFUNAduAGcPGnAWsqarnkhzatH0iyZokNyR5zSjmIsmFSQaTDG7evLmPMiRJ/ZqQC9JJjqVzeuj9TdNUYBbwzapaCHwLuGw0c1bVlVU1UFUDM2fOHNf1StK+rp9weBI4umt7VtPWc0ySqcAhwNZmexZwE3BuVT3ajN8K/Ai4sdm+AVg40lySpInRTzjcCxyTZE6S/YElwKphY1bRueAMsBi4o6qqOX10K7C8qu7eObiqCrgFOLlpOgV46OXmGk1RkqSxmTrSgKoaSrIMuA2YAlxdVeuSXAIMVtUq4Crg2iQbgKfpBAjAMmAusCLJiqbtHVX1FPDRZp8rgM3A7zT9LzWXJGmCZG94Uj4wMFCDg4O7exmSNKkkWV1VA736/AtpSVKL4SBJajEcJEkthoMkqcVwkCS1GA6SpBbDQZLUYjhIkloMB0lSi+EgSWoxHCRJLYaDJKnFcJAktRgOkqQWw0GS1GI4SJJaDAdJUovhIElq2Ss+JjTJZuD7u3sdPRwObNndi9hN9uXaYd+u39onj1+sqpm9OvaKcNhTJRl8qc9n3dvty7XDvl2/te8dtXtaSZLUYjhIkloMh1fWlbt7AbvRvlw77Nv1W/tewGsOkqQWjxwkSS2GgySpxXDYBUmOTvKNJA8lWZfk3/YYsyjJA0nWJhlM8uauvqVJvtfclk7s6sdmHGr/p6Z9bZJVE7v6semn9q6xJyYZSrK4q23SPu4wLvXv1Y99kpOTbOuqcUVX32lJ1ifZkGT5xK5+F1WVt1HegCOBhc39g4C/BeYPG/Pz/OyazgLgkeb+q4HHmq+HNfcP2901TUTtzfYPd3cNr2TtTd8U4A7gq8DiveFxH2v9+8JjD5wM/M+X+Pd4FHgtsD9wf69/tz3t5pHDLqiqv6+qNc397cDDwFHDxvywmp8M4EBg5/3fAL5eVU9X1TPA14HTJmblYzfG2ie1fmpv/D7w34Gnutom9eMOY65/UhtF7b2cBGyoqseq6nngOmDRK7PS8WM4jFGS2cAbgXt69J2Z5BHgVuD8pvko4ImuYRvp/4dsj7ILtQNMb041fTvJb07IQl8BL1V7kqOAM4HPD9tlr3ncYZfqh738sW/8yyT3J/lfSY5t2iblY284jEGSn6fzDOmiqvrB8P6quqmqfhn4TeATE7y8V9QYav/F6ry9wG8BVyT5pYlY73gaofYrgI9W1U8mfGETZAz17+2P/Ro6Nb4B+Axw8wQvb1wZDrsoyX50fkj+a1Xd+HJjq+pO4LVJDgeeBI7u6p7VtE0aY6idqnqy+foY8L/pPAObNPqofQC4LsnjwGLgc82z5En/uMOY6t/rH/uq+kFV/bC5/1Vgv0n9O7+7L3pMxhsQ4K+AK15mzFx+dlF2IZ0fhtC5IPl3dC5KHtbcf/XurmmCaj8MmNa0Hw58j0lwYW40tQ8b/yVefEF60j7u41D/Xv/YA/+s6+f+JOD/NvtNpfMChDn87IL0sbu7ppFuU0edJgL4NeC3gQeTrG3a/j3wzwGq6i+Bs4Bzk7wA/Bg4uzo/NU8n+QRwb7PfJVX19EQufox2ufYkrwf+c5Kf0Dlq/bOqemiiCxiDfmrvqaom++MOY6gf2Bce+8XAB5MM0fm5X9L8zg8lWQbcRueVS1dX1boJXv+o+fYZkqQWrzlIkloMB0lSi+EgSWoxHCRJLYaDJO1hklyd5Kkk3x2n+S5N8t3mdnY/+xgO0issyUVJDtjd69Ck8iXG6b23kvwrOn9vdDzwL4CPJDl4pP0MB2kcpOOlfp8uAgwH9a067yzwor+DSfJLSb6WZHWSu5L8cp/TzQfurKqhqvpH4AH6CB7DQdpFSWY379H/V8B3gauaN5Zbl+TiZsyHgF8AvpHkG03bO5J8K8maJDc079cjjeRK4Per6gTgI8Dn+tzvfuC0JAc0b+fxVl78dh49+RfS0tgcAyytqm8neXXzl9BTgNuTLKiqTyf5MPDWqtrS/HL+MfD2qvrHJB8FPgxcshtr0B6ueQLxq8ANSXY2T2v63kPvn58nq+o3quqvk5wIfBPYDHwL+KeRvqfhII3N96vq28399yW5kM7v1ZF0DucfGDb+TU373c0v+f50flmll/NzwLNVdfzwjuq8CeBIb4D5SeCTAEn+G50PK3pZhoM0Nv8IkGQOnUP9E6vqmSRfAqb3GB86H/pzzsQtUZNdVf0gyd8leW9V3ZDOM4sFVXX/SPs2R7KHVtXWJAvofDrjX4+0n9ccpPFxMJ2g2JbkNcA7u/q20/loSYBvA7+WZC5AkgOTzJvQlWqPl+TLdI4oX5dkY5ILgH8NXJDkfmAd/X+a3H7AXUkeonPd4t9U1dBIO3nkII2Dqro/yX3AI3Q+9evuru4rga8l2VRVb01yHvDlJNOa/j+mj8N87Tte5shy1C9vraoddE5ljorvyipJavG0kiSpxXCQJLUYDpKkFsNBktRiOEiSWgwHSVKL4SBJavn/+PA2DMDWvaYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stochSys.cumsum()\n",
    "stochSys.plot(x=\"rate\", y='distortion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pareto Frontier\n",
    "Now let's run the Information Bottleneck Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# The structural phase transitions along the pareto frontier\n",
    "stochSys = []\n",
    "for i, q in enumerate(zip(qseq, qseqresults)):\n",
    "    for w in mergecols(q[0]).transpose():\n",
    "        stochSys.append([len(qseq)-i, q[1][0], q[1][1]] + list(w))\n",
    "\n",
    "stochSys = pd.DataFrame(data=np.array(stochSys), columns = ['n', 'rate', 'distortion'] + items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "# compute distance from optimal frontier\n",
    "def fd(asys, ibscores):\n",
    "    mind = distance.cdist([[asys['rate'], asys['distortion']]], ibscores[['rate', 'distortion']]).min()\n",
    "    return mind\n",
    "\n",
    "\n",
    "def gNID_d(asys, paretoQs, betas, pX):\n",
    "    mind = np.zeros((len(asys), len(paretoQs)))\n",
    "    for li in range(len(asys)):\n",
    "        for qi, q in enumerate(paretoQs):\n",
    "            mind[li, qi] = gNID(asys.iloc[li]['q'], q, pX)\n",
    "    return np.argmin(mind, axis=1), np.min(mind, axis=1), betas[np.argmin(mind, axis=1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbda1052f39ca0b0a0cd74911b0c91c0e224307f85d570c8823d0661ac0877c0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('lc': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
