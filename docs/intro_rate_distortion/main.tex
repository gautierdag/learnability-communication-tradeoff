\documentclass[11pt]{article}
\usepackage{ACL}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{enumitem}
\usepackage{subfigure}
\usepackage{graphicx}
\input{math_commands.tex}
\usepackage{bbm}
\usepackage{amssymb}

\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here


\title{Modelling Language Communication and Learning with \\ Rate Distortion Theory}

\author{Team members} 

% 2. Two rows of authors (set titlebox length to 7cm)
%
% \author{First Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  {\tt email@domain} \\\And
%  Second Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  {\tt email@domain} \\\AND
%  Third Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  {\tt email@domain} \\\And
%  Fourth Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  {\tt email@domain} \\}
%
% 3. More than four authors (set titlebox length to 7cm or more)
%
%\author{First Author$^{1}$, Second Author$^{2}$, Third Author$^{3}$, Fourth Author$^{1,4}$,\\
%\textbf{Fifth Author$^{2}$, Sixth Author$^{5}$, Seventh Author$^{6}$, Eighth Author$^{7}$}\\
%[0.5cm] 
%$^{1}$Affiliation 1, Affiliation / Address line 2, Affiliation / Address line 3, {\tt email@domain} \\
%$^{2}$Affiliation 2, Affiliation / Address line 2, Affiliation / Address line 3, {\tt email@domain} \\
%$^{3}$Affiliation 3, Affiliation / Address line 2, Affiliation / Address line 3, {\tt email@domain} \\
%$^{4}$Affiliation 4, Affiliation / Address line 2, Affiliation / Address line 3, {\tt email@domain} \\
%$^{5}$Affiliation 5, Affiliation / Address line 2, Affiliation / Address line 3, {\tt email@domain} \\
%$^{6}$Affiliation 6, Affiliation / Address line 2, Affiliation / Address line 3, {\tt email@domain} \\
%$^{7}$Affiliation 7, Affiliation / Address line 2, Affiliation / Address line 3, {\tt email@domain} \\}
%
\date{}

\begin{document}
\maketitle
\begin{abstract}
  This document describes the basic concepts and [to be written].
\end{abstract}

\section{Universal Components}
\label{sec:uni_components}

% \subsection{Variables and Functions}
% \label{ssec:vars_funcs}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.49\textwidth]{docs/intro_rate_distortion/graphs/cog_comm_dag.pdf}
    \caption{Illustration of our setting in a DAG.}
    \label{fig:pipeline_dag}
\end{figure}

To better illustrate the problem, we need to start from the directed acyclic graph (DAG) shown in Figure~\ref{fig:pipeline_dag}.
The variables involved in the DAG are listed as follows:

\begin{itemize}[leftmargin=*]
    \item \textbf{meaning $m\in\mathcal{M}$\footnote{In this document, the set of a variable is notated by the corresponding calligraphic capital letter.}}: a meaning $m$ is \textcolor{red}{a discrete variable} indicating the possible meanings.
    It specifies both distributions over $c$, i.e. $q(c|m)$, and distributions over words $w$, i.e. $q(w|m)$.
    In fact, \textcolor{red}{$m$ is the core variable in our project}, and it corresponds to the source variable $x$ in the standard information theory model.
    
    We don't know the size of meaning space $|\mathcal{M}|$ nor $p(m)$ for each $m$.
    In both communication problem and learning problem, we have to infer that out.
    Or, in the language of probabilistic graphical model, $m$ is a latent variable in our setup.
    We will also show in the Section~\ref{sec:comm}and~\ref{sec:learning} that $p(m)$ can be inferred out by algorithms similar to Expectation-Maximisation. 

    \item \textbf{colour chip $c\in\mathcal{C}$}: a colour chip is also a discrete integer variable indicating the possible values of colours. 
    $\mathcal{C}$ is given in the data set, and it keeps identical across different languages (defined below). 
    The colour palette $\mathcal{C}$ we're going to use is shown in Figure~\ref{fig:colour_palette}, where each grid corresponds to a specific $c$.
        \begin{figure}[h]
            \centering
            \includegraphics[width=0.49\textwidth]{docs/intro_rate_distortion/graphs/colour_palette.jpg}
            \caption{Colour palette introduced by \citet{berlin1991basic}}
            \label{fig:colour_palette}
        \end{figure}
        
    In this project, we will ignore the variable $u$ (``universe'') used by \citet{zaslavsky2018efficient} because the entire universe is constrained to the colour palette. 
    Mathematically, $\mathcal{U}$ is just a superset of $\mathcal{C}$ which represents the objects in the universe.
    
    Same to \cite{zaslavsky2018efficient}, given a meaning $m$, we assume the conditional distribution of $c$ is a Gaussian centred at $\rc(m)$, i.e.:
    \begin{align}
    q(c|m)\propto \exp{-\frac{1}{\sigma^2}}||c-\rc(m)||^2    
    \end{align}
    
    An example is given in Figure~\ref{fig:green_meaning}.
        \begin{figure}[h]
            \centering
            \includegraphics[width=0.49\textwidth]{docs/intro_rate_distortion/graphs/green_meaning.png}
            \caption{Meaning of ``green'' which is a Gaussian distribution over different colour chips.}
            \label{fig:green_meaning}
        \end{figure}
        
    \item \textbf{word $w\in\mathcal{W}$}: a discrete variable transmitted from speaker to listener. 
    We can give each value a name, e.g. ``blue'' for the 3rd value.
    However, this is not necessary here since we do not care what actual word is used for some meaning. Sometimes, $\mathcal{W}$ is referred to as ``dictionary'', ``vocabulary'', or ``lexicon''.
    Since the conditional distribution $q(w|c)$ has a name and it's an important concept in this project, so we illustrate it in the following separately.
    
    \item \textbf{language $q(w|m)$}: a language is the distribution of words conditioned on meanings, i.e. a language tells us the probability of emitting a word $w$ given a meaning $m$.
    It is a.k.a. the \emph{encoder} in standard information theory terminology, and can also be written as a function $L:\mathcal{M}\rightarrow\mathcal{W}$.
        \begin{figure}[h]
            \centering
            \includegraphics[width=0.49\textwidth]{docs/intro_rate_distortion/graphs/color_language.png}
            \caption{English on the colour palette from \citet{berlin1991basic}.
            }
            \label{fig:language_example}
        \end{figure}
    
    An example based on English is illustrated in Figure~\ref{fig:language_example}.
    To be specific, the colour chips in the green region will all be referred by the word ``green''.
    The boundary is hard in this example, but the naming policy $q(w|m)$ can have soft boundaries, e.g. by using Gaussian distribution.
    
    \item \textbf{interpretation policy $q(\hat{m}|w)$\label{par:decoder}}: an interpretation specifies the distribution of colour chips given a specific word, a.k.a. \emph{decoder} in standard information theory terminology, and can also be written as a function $I:\mathcal{W}\rightarrow\mathcal{C}$.
    Note we use $\hat{m}$ here instead of $m$ because the two random variables have different probability mass although they have the same sample space. 
    $\hat{m}$ is the understood or reconstructed meaning from the word $w$.
    For example, after receiving the word ``green'', we could have a distribution over all colours that is very similar to the one in Figure~\ref{fig:green_meaning} but more skewed towards blue.
    
    The $q(\hat{m}|w)$ used by \citet{zaslavsky2018efficient} is a Bayesian learner defined as follow:
    \begin{equation}
        q(\hat{m}|w) \propto q(w|m)p(m)
        \label{eq:bayesian_interpretation}
    \end{equation}
    That is, we can determine $q(\hat{m}|w)$ once we have an established $q(w|m)$ and $p(m)$.
    
    
\end{itemize}

\section{Communication Problem}
\label{sec:comm}

We first illustrate communication problem as all members are more familiar with it and there is no unique variable involved in it.
Our aim in communication part of this project is to give a diagram similar to the one sketched in Figure~\ref{fig:curve_comm}.
The red line in the figure is referred as ``frontier'', and our aim is to show that it is indeed a trade-off curve.
The calculation of each axes and the curve itself are illustrated in the following subsections.

Meanwhile, it is very important to realise that we're going to \textcolor{red}{optimise both $q(w|m)$ and $p(m)$} in the commutation problem to reduce the information loss defined in Section~\ref{ssec:lan_info_loss}.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.49\textwidth]{docs/intro_rate_distortion/graphs/communication_curve.pdf}
    \caption{The curve we aim to plot in the communication problem.}
    \label{fig:curve_comm}
\end{figure}

\subsection{Pipeline}
\label{ssec:pipeline}

The pipeline of our model is shown in Figure~\ref{fig:pipeline}, where $\mathcal{E}$ denotes the error/loss function we're going to use.
Note that there's no $c$ involved in the diagram, since $c$ is not a part of communication but a part of the metric used for evaluating the loss during communication.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.49\textwidth]{docs/intro_rate_distortion/graphs/cog_communication.pdf}
    \caption{The pipeline of our model.}
    \label{fig:pipeline}
\end{figure}

In the existing works, the common choices of $\mathcal{E}$ are indicator function $\mathbbm{1}(\hat{m}=m)$ and $KL$-divergence $D[q(c|\hat{m},w)||q(c|m)]$.
since we're going to use $KL$-divergence, the full form of it is given as follow:

\begin{equation}
\begin{split}
    & \mathcal{E}(\hat{m}, m) \triangleq  D[\hat{m}||m] \\
    & = D[q(c|\hat{m},w)||q(c|m)]  \\
    & = \sum_{c} q(c|m) \log \frac{q(c|m)}{q(c|\hat{m},w)} \\
    & = \sum_{c} q(c|m) \log \frac{q(c|m)}{q(c|\hat{m})q(\hat{m}|w)}
\end{split}
\label{eq:comm_loss_function}
\end{equation}

The distortion (a.k.a. information loss with $D[\hat{m}||m]$) is then defined by the expectation of our error/loss function, i.e.

\begin{equation}
    \mathbb{E}_{m,\hat{m}}\left[\mathcal{E}(\hat{m},m)\right]
    \label{eq:distortion}
\end{equation}


\subsection{Complexity of Languages}
\label{ssec:complexity}

The complexity of our a language is defined as the mutual information between $m$ and $w$, i.e. 

\begin{equation}
    I(M;W) = \sum_{m,w} p(m)q(w|m)\log \frac{q(w|m)}{q(w)}
    \label{eq:complexity_definition}
\end{equation}

Given $p(m)$, the amount of information conveyed by it can be measured by the entropy of it, i.e. $H(M)$.
With $H(M)=I(M;W)+H(M|W)$, it is then straightforward to see that $I(M;W)$ is how many extra information about $m$ conveyed by $w$, i.e. the amount of information conveyed in the channel/language.
Assuming that more information means higher complexity, then the complexity of a language can be measured by $I(M;W)$, or at least, there is a positive correlation between the two quantities.

Therefore, once we have a $q(w|m)$, we can calculate its complexity by simply following Equation~\ref{eq:complexity_definition}.
We will show later how to derive such a $q(w|m)$ in Section~\ref{ssec:comm_opt_ib}.

\subsection{Information Loss of Languages}
\label{ssec:lan_info_loss}

As we illustrated in the interpretation policy, given a language and a learner architecture, we can derive $q(\hat{m}|w)$.
Then, the joint distribution of $\hat{m}$ and $m$ is as follow:

\begin{equation}
    \begin{split}
        q(\hat{m},m) 
        & = q(\hat{m}|m)p(m) \\
        & = \sum_w q(\hat{m}|w)q(w|m)p(m)
    \end{split}
    \label{eq:joint_c_hat_c}
\end{equation}

Combining the above equation with Equation~\ref{eq:distortion}, the information loss can then be calculated as:

\begin{equation}
    \begin{split}
        & \mathbb{E}_{q(\hat{m},m)}\left[D[\hat{m}||m]\right] \\
        & = \mathbb{E}_{q(\hat{m},m)}\left[ \sum_{c} q(c|m) \log \frac{q(c|m)}{q(c|\hat{m}, w)} \right] \\
        & = \sum_{\hat{m},m} q(\hat{m}|m)p(m)\sum_{c} q(c|m)\log\frac{q(c|m)}{q(c|\hat{m})q(\hat{m}|w)} \\
        & = \sum_{\hat{m},m,w} q(\hat{m}|w)q(w|m)p(m)\sum_{c} q(c|m)\log\frac{q(c|m)}{q(c|\hat{m})q(\hat{m}|w)} \\
        & = \sum_{\hat{m},m,c,w}q(\hat{m}|w)q(w|m)p(m)q(c|m)\log\frac{q(c|m)}{q(c|\hat{m})q(\hat{m}|w)}
    \end{split}
    \label{eq:comm_info_loss}
\end{equation}

\subsection{Optimising Information Bottleneck}
\label{ssec:comm_opt_ib}

So far, everything seems fine with a given language $q(w|m)$ and a given distribution of meanings $p(m)$.
But, there is still one question: how could we get them?

To do so, we going to optimise the information bottleneck (IB) objective function as follow:



\section{Learning Problem}
\label{sec:learning}

Infer $p(m)$ given $(c,w)$ pairs.

\section{Dataset}
\label{sec:dataset}


\bibliographystyle{acl_natbib}
\bibliography{main}

\end{document}
